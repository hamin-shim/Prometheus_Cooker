{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499 499\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {'text':[], 'label':[]}\n",
    "df = pd.read_excel('./sampled.xlsx')\n",
    "df['DATA'] = df['DATA'].fillna('')\n",
    "for dt, label in zip(df['DATA'], df['TARGET']):\n",
    "    try: \n",
    "        data['label'].append(int(label))\n",
    "        data['text'].append(dt)\n",
    "    except: pass\n",
    "print(len(data['text']), len(data['label']))\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ìœ ëŸ½ì—ì„œëŠ” ê²¨ìš¸ì² ë§Œ ë˜ë©´  ë‚¨ì—¬ë…¸ì†Œ ë±…ì‡¼ë¥¼ ì¦ê¸´ë‹¤ê³  í•´ìš”~ ì™€ì¸ì— ê³¼ì¼ì„ ë„£ê³  í‘¹ë“...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ë¹¨ê°„ ìˆœë‘ë¶€ë§Œ ë¨¹ë‹¤ê°€... ê»ì§ˆë²—ê¸´ ë“¤ê¹¨ê°€ë£¨ë¥¼ ë„£ì–´ ì˜ì–‘ì„ ë”í•´ë³´ë‹ˆ ë³´ì–‘ì‹ì´ ë”°ë¡œ ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ê³ ê¸°ì™€ ì–‘ë…ë§Œ ìˆìœ¼ë©´ ì–´ë””ì„œë“  ì‰½ê²Œ ë§Œë“¤ì–´ ë¨¹ì„ ìˆ˜ ìˆì–´ìš”. ìº í•‘ì˜ ê½ƒì€ ê³ ê¸°!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ì•„ë“¤ì´ ë¨¹ê³  ì‹¶ë‹¤ëŠ” ê³¨ë±…ì´ë¬´ì¹¨ì— ì†Œë©´ì„ ê³ë“¤ì—¬ í•œë¼ ì‹ì‚¬ë¡œ ì¶©ë¶„</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ì‚¬ê³¼ëŠ” ì‹ì´ì„¬ìœ ê°€ ë§ê³  ë‹¤ë‹¹ë¥˜ ë¹„ìœ¨ì´ ë†’ì•„ì„œ ë‹¤ì´ì–´íŠ¸ì—ë„ ë„ì›€ì´ ë˜ë©°  íŠ¹íˆ ì‚¬ê³¼ ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>ê°•íŒì— ê°ˆì•„ì„œ ë§Œë“œëŠ” ê°ìì „ì€ ë§ì´ ì•Œê³  ê³„ì‹¤í…ë°ìš”. ê°ìë¥¼ ê°ˆì§€ ì•Šê³  ì±„ë¥¼ ì°ì–´ì„œ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>http://blog.naver.com/chez_sophie</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>íŒŒí‹°ì— íŠ€ê¹€ìš”ë¦¬ ì—†ìœ¼ë©´ í—ˆì „í•˜ì£ . ì–¸ì œë‚˜ ë§›ìˆëŠ” íŠ€ê¹€ìš”ë¦¬  ëª¨ì–‘ë„ ì´ì˜ê³  ì™„ì „ ë°”ì‚­...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>ë‚¨í¸ì´ ì¢‹ì•„í•˜ëŠ” ì‹œì›í•œ ì¬ì²©êµ­ì„ ë¯¸ì†Œ ëœì¥ì„ í’€ì–´ êµ¬ìˆ˜í•˜ê³  ë‹´ë°±í•˜ê²Œ ë“ì˜€ëŠ”ë° ì •ë§ ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>ë¶ˆì„ ì“°ì§€ì•Šê³  ë§Œë“œëŠ” ì°¸ì¹˜ê¹€ë°¥ì€ ë‹¨ì´›ë¬¼ì— ë²„ë¬´ë¦° ì´ˆë°¥ê³¼ ë§ˆìš”ë„¤ì¦ˆ ì—†ì´ ê¹”ë”í•˜ê²Œ ë§›ì„...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "0    ìœ ëŸ½ì—ì„œëŠ” ê²¨ìš¸ì² ë§Œ ë˜ë©´  ë‚¨ì—¬ë…¸ì†Œ ë±…ì‡¼ë¥¼ ì¦ê¸´ë‹¤ê³  í•´ìš”~ ì™€ì¸ì— ê³¼ì¼ì„ ë„£ê³  í‘¹ë“...      1\n",
       "1    ë¹¨ê°„ ìˆœë‘ë¶€ë§Œ ë¨¹ë‹¤ê°€... ê»ì§ˆë²—ê¸´ ë“¤ê¹¨ê°€ë£¨ë¥¼ ë„£ì–´ ì˜ì–‘ì„ ë”í•´ë³´ë‹ˆ ë³´ì–‘ì‹ì´ ë”°ë¡œ ...      1\n",
       "2         ê³ ê¸°ì™€ ì–‘ë…ë§Œ ìˆìœ¼ë©´ ì–´ë””ì„œë“  ì‰½ê²Œ ë§Œë“¤ì–´ ë¨¹ì„ ìˆ˜ ìˆì–´ìš”. ìº í•‘ì˜ ê½ƒì€ ê³ ê¸°!      0\n",
       "3                  ì•„ë“¤ì´ ë¨¹ê³  ì‹¶ë‹¤ëŠ” ê³¨ë±…ì´ë¬´ì¹¨ì— ì†Œë©´ì„ ê³ë“¤ì—¬ í•œë¼ ì‹ì‚¬ë¡œ ì¶©ë¶„      0\n",
       "4    ì‚¬ê³¼ëŠ” ì‹ì´ì„¬ìœ ê°€ ë§ê³  ë‹¤ë‹¹ë¥˜ ë¹„ìœ¨ì´ ë†’ì•„ì„œ ë‹¤ì´ì–´íŠ¸ì—ë„ ë„ì›€ì´ ë˜ë©°  íŠ¹íˆ ì‚¬ê³¼ ...      0\n",
       "..                                                 ...    ...\n",
       "494  ê°•íŒì— ê°ˆì•„ì„œ ë§Œë“œëŠ” ê°ìì „ì€ ë§ì´ ì•Œê³  ê³„ì‹¤í…ë°ìš”. ê°ìë¥¼ ê°ˆì§€ ì•Šê³  ì±„ë¥¼ ì°ì–´ì„œ...      1\n",
       "495                  http://blog.naver.com/chez_sophie      0\n",
       "496  íŒŒí‹°ì— íŠ€ê¹€ìš”ë¦¬ ì—†ìœ¼ë©´ í—ˆì „í•˜ì£ . ì–¸ì œë‚˜ ë§›ìˆëŠ” íŠ€ê¹€ìš”ë¦¬  ëª¨ì–‘ë„ ì´ì˜ê³  ì™„ì „ ë°”ì‚­...      0\n",
       "497  ë‚¨í¸ì´ ì¢‹ì•„í•˜ëŠ” ì‹œì›í•œ ì¬ì²©êµ­ì„ ë¯¸ì†Œ ëœì¥ì„ í’€ì–´ êµ¬ìˆ˜í•˜ê³  ë‹´ë°±í•˜ê²Œ ë“ì˜€ëŠ”ë° ì •ë§ ...      1\n",
       "498  ë¶ˆì„ ì“°ì§€ì•Šê³  ë§Œë“œëŠ” ì°¸ì¹˜ê¹€ë°¥ì€ ë‹¨ì´›ë¬¼ì— ë²„ë¬´ë¦° ì´ˆë°¥ê³¼ ë§ˆìš”ë„¤ì¦ˆ ì—†ì´ ê¹”ë”í•˜ê²Œ ë§›ì„...      1\n",
       "\n",
       "[499 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee5592c00a7483f828cf28ccc6d1d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\envs\\unet\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user\\.cache\\huggingface\\hub\\models--bert-base-multilingual-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f78963bfa706499fa36b0b7e2c75384c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a6f5f32fb842c390441e1431e47745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.72M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1738dec853a04995869b2eb3e17a2130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca6a9a04d5e4fdb9b81913e3451e8e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/672M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\user\\miniconda3\\envs\\unet\\lib\\site-packages\\transformers\\training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b15624980b64cafaf2bc0ca94c7231f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6994, 'grad_norm': 1.489874243736267, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.4}\n",
      "{'loss': 0.7022, 'grad_norm': 4.360358238220215, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e63e849e08024bb0b83b7fb2bb1047e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6978673338890076, 'eval_runtime': 1.3414, 'eval_samples_per_second': 74.547, 'eval_steps_per_second': 5.218, 'epoch': 1.0}\n",
      "{'loss': 0.6991, 'grad_norm': 0.9928870797157288, 'learning_rate': 3e-06, 'epoch': 1.2}\n",
      "{'loss': 0.6932, 'grad_norm': 2.0515236854553223, 'learning_rate': 4.000000000000001e-06, 'epoch': 1.6}\n",
      "{'loss': 0.6884, 'grad_norm': 2.379213333129883, 'learning_rate': 5e-06, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8de58b32a3e4709a6d9338ef618ef24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6824386715888977, 'eval_runtime': 1.2266, 'eval_samples_per_second': 81.525, 'eval_steps_per_second': 5.707, 'epoch': 2.0}\n",
      "{'loss': 0.6835, 'grad_norm': 1.9411474466323853, 'learning_rate': 6e-06, 'epoch': 2.4}\n",
      "{'loss': 0.6903, 'grad_norm': 3.7308666706085205, 'learning_rate': 7.000000000000001e-06, 'epoch': 2.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb57921e58b4ec889b4269d6c0b0d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6723256707191467, 'eval_runtime': 1.2996, 'eval_samples_per_second': 76.949, 'eval_steps_per_second': 5.386, 'epoch': 3.0}\n",
      "{'loss': 0.6785, 'grad_norm': 6.351012706756592, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.2}\n",
      "{'loss': 0.6513, 'grad_norm': 2.6637585163116455, 'learning_rate': 9e-06, 'epoch': 3.6}\n",
      "{'loss': 0.6471, 'grad_norm': 5.3540496826171875, 'learning_rate': 1e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa2627f2556c46b1b5d867a427dc8ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6521072387695312, 'eval_runtime': 1.2912, 'eval_samples_per_second': 77.447, 'eval_steps_per_second': 5.421, 'epoch': 4.0}\n",
      "{'loss': 0.5742, 'grad_norm': 5.023708343505859, 'learning_rate': 1.1000000000000001e-05, 'epoch': 4.4}\n",
      "{'loss': 0.6143, 'grad_norm': 5.1458306312561035, 'learning_rate': 1.2e-05, 'epoch': 4.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "165a06998ff54bc88b094bc100e39018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6555801630020142, 'eval_runtime': 1.2965, 'eval_samples_per_second': 77.129, 'eval_steps_per_second': 5.399, 'epoch': 5.0}\n",
      "{'loss': 0.5121, 'grad_norm': 7.896594047546387, 'learning_rate': 1.3000000000000001e-05, 'epoch': 5.2}\n",
      "{'loss': 0.4446, 'grad_norm': 10.803801536560059, 'learning_rate': 1.4000000000000001e-05, 'epoch': 5.6}\n",
      "{'loss': 0.4462, 'grad_norm': 17.094953536987305, 'learning_rate': 1.5e-05, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a6aa1b83197421d8f99fbbd8b2b10eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6141784191131592, 'eval_runtime': 1.2229, 'eval_samples_per_second': 81.775, 'eval_steps_per_second': 5.724, 'epoch': 6.0}\n",
      "{'loss': 0.3151, 'grad_norm': 8.143608093261719, 'learning_rate': 1.6000000000000003e-05, 'epoch': 6.4}\n",
      "{'loss': 0.2843, 'grad_norm': 9.92552375793457, 'learning_rate': 1.7000000000000003e-05, 'epoch': 6.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2752e2c73eb449d78b7a4544ffeb6335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6996975541114807, 'eval_runtime': 1.2825, 'eval_samples_per_second': 77.97, 'eval_steps_per_second': 5.458, 'epoch': 7.0}\n",
      "{'loss': 0.262, 'grad_norm': 35.67045593261719, 'learning_rate': 1.8e-05, 'epoch': 7.2}\n",
      "{'loss': 0.2249, 'grad_norm': 7.856639385223389, 'learning_rate': 1.9e-05, 'epoch': 7.6}\n",
      "{'loss': 0.2193, 'grad_norm': 17.420120239257812, 'learning_rate': 2e-05, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e18fa5ad19457792f5b5579308c95e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.712668776512146, 'eval_runtime': 1.2277, 'eval_samples_per_second': 81.452, 'eval_steps_per_second': 5.702, 'epoch': 8.0}\n",
      "{'loss': 0.2191, 'grad_norm': 27.594871520996094, 'learning_rate': 2.1e-05, 'epoch': 8.4}\n",
      "{'loss': 0.1499, 'grad_norm': 1.6906510591506958, 'learning_rate': 2.2000000000000003e-05, 'epoch': 8.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba02b6d3a3c44249bcb8aead704806a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7382239699363708, 'eval_runtime': 1.2846, 'eval_samples_per_second': 77.847, 'eval_steps_per_second': 5.449, 'epoch': 9.0}\n",
      "{'loss': 0.0695, 'grad_norm': 0.5173003673553467, 'learning_rate': 2.3000000000000003e-05, 'epoch': 9.2}\n",
      "{'loss': 0.1293, 'grad_norm': 44.86957550048828, 'learning_rate': 2.4e-05, 'epoch': 9.6}\n",
      "{'loss': 0.0853, 'grad_norm': 4.403032302856445, 'learning_rate': 2.5e-05, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1f38fde0834720bd4e43025471b332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3389713764190674, 'eval_runtime': 1.2329, 'eval_samples_per_second': 81.108, 'eval_steps_per_second': 5.678, 'epoch': 10.0}\n",
      "{'loss': 0.0282, 'grad_norm': 0.26380228996276855, 'learning_rate': 2.6000000000000002e-05, 'epoch': 10.4}\n",
      "{'loss': 0.1489, 'grad_norm': 56.05681610107422, 'learning_rate': 2.7000000000000002e-05, 'epoch': 10.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d02c1543534faab43b68890b98b69a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1602096557617188, 'eval_runtime': 1.2846, 'eval_samples_per_second': 77.846, 'eval_steps_per_second': 5.449, 'epoch': 11.0}\n",
      "{'loss': 0.0661, 'grad_norm': 1.4353855848312378, 'learning_rate': 2.8000000000000003e-05, 'epoch': 11.2}\n",
      "{'loss': 0.1625, 'grad_norm': 17.116079330444336, 'learning_rate': 2.9e-05, 'epoch': 11.6}\n",
      "{'loss': 0.2064, 'grad_norm': 32.79188919067383, 'learning_rate': 3e-05, 'epoch': 12.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ea2abb75c7441f58132fa4e1b2783b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.361907958984375, 'eval_runtime': 1.2357, 'eval_samples_per_second': 80.924, 'eval_steps_per_second': 5.665, 'epoch': 12.0}\n",
      "{'loss': 0.078, 'grad_norm': 28.466552734375, 'learning_rate': 3.1e-05, 'epoch': 12.4}\n",
      "{'loss': 0.0743, 'grad_norm': 36.8537483215332, 'learning_rate': 3.2000000000000005e-05, 'epoch': 12.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0928659c86c745af85beeec8826601ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1831129789352417, 'eval_runtime': 1.2786, 'eval_samples_per_second': 78.212, 'eval_steps_per_second': 5.475, 'epoch': 13.0}\n",
      "{'loss': 0.0723, 'grad_norm': 0.18570154905319214, 'learning_rate': 3.3e-05, 'epoch': 13.2}\n",
      "{'loss': 0.1069, 'grad_norm': 0.05952151119709015, 'learning_rate': 3.4000000000000007e-05, 'epoch': 13.6}\n",
      "{'loss': 0.0867, 'grad_norm': 0.26539167761802673, 'learning_rate': 3.5e-05, 'epoch': 14.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "845f1ca6ccba4502b29fa23f736420ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.950630784034729, 'eval_runtime': 1.2487, 'eval_samples_per_second': 80.086, 'eval_steps_per_second': 5.606, 'epoch': 14.0}\n",
      "{'loss': 0.0196, 'grad_norm': 36.25295639038086, 'learning_rate': 3.6e-05, 'epoch': 14.4}\n",
      "{'loss': 0.1469, 'grad_norm': 0.15658098459243774, 'learning_rate': 3.7e-05, 'epoch': 14.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf024bf106d441c9adbaba0965c16695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.9160352945327759, 'eval_runtime': 1.3107, 'eval_samples_per_second': 76.297, 'eval_steps_per_second': 5.341, 'epoch': 15.0}\n",
      "{'loss': 0.1094, 'grad_norm': 26.97079086303711, 'learning_rate': 3.8e-05, 'epoch': 15.2}\n",
      "{'loss': 0.207, 'grad_norm': 107.04776000976562, 'learning_rate': 3.9000000000000006e-05, 'epoch': 15.6}\n",
      "{'loss': 0.114, 'grad_norm': 0.09239620715379715, 'learning_rate': 4e-05, 'epoch': 16.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f09ba60f7fdd442a9a9e553478c8658a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.0516481399536133, 'eval_runtime': 1.2377, 'eval_samples_per_second': 80.795, 'eval_steps_per_second': 5.656, 'epoch': 16.0}\n",
      "{'loss': 0.1786, 'grad_norm': 21.412633895874023, 'learning_rate': 4.1e-05, 'epoch': 16.4}\n",
      "{'loss': 0.1862, 'grad_norm': 0.2494419664144516, 'learning_rate': 4.2e-05, 'epoch': 16.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b70c3f3ed6472f989576e644aabc9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3168127536773682, 'eval_runtime': 1.2975, 'eval_samples_per_second': 77.069, 'eval_steps_per_second': 5.395, 'epoch': 17.0}\n",
      "{'loss': 0.0456, 'grad_norm': 0.7388060092926025, 'learning_rate': 4.3e-05, 'epoch': 17.2}\n",
      "{'loss': 0.0059, 'grad_norm': 0.020894650369882584, 'learning_rate': 4.4000000000000006e-05, 'epoch': 17.6}\n",
      "{'loss': 0.2843, 'grad_norm': 34.72737121582031, 'learning_rate': 4.5e-05, 'epoch': 18.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33825b5d318c431cbdb9e3be9e161296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1165876388549805, 'eval_runtime': 1.2307, 'eval_samples_per_second': 81.254, 'eval_steps_per_second': 5.688, 'epoch': 18.0}\n",
      "{'loss': 0.1807, 'grad_norm': 8.880483627319336, 'learning_rate': 4.600000000000001e-05, 'epoch': 18.4}\n",
      "{'loss': 0.1785, 'grad_norm': 0.5960952639579773, 'learning_rate': 4.7e-05, 'epoch': 18.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ca243dab1b4caaa0074c100b0474ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6285836696624756, 'eval_runtime': 1.3085, 'eval_samples_per_second': 76.422, 'eval_steps_per_second': 5.35, 'epoch': 19.0}\n",
      "{'loss': 0.0216, 'grad_norm': 0.05761074274778366, 'learning_rate': 4.8e-05, 'epoch': 19.2}\n",
      "{'loss': 0.1249, 'grad_norm': 0.022513478994369507, 'learning_rate': 4.9e-05, 'epoch': 19.6}\n",
      "{'loss': 0.1002, 'grad_norm': 0.053915027529001236, 'learning_rate': 0.0, 'epoch': 20.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae961429da8a424390cf799f9408f354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6156260967254639, 'eval_runtime': 1.2972, 'eval_samples_per_second': 77.088, 'eval_steps_per_second': 5.396, 'epoch': 20.0}\n",
      "{'train_runtime': 262.8466, 'train_samples_per_second': 30.36, 'train_steps_per_second': 1.902, 'train_loss': 0.2863356233239174, 'epoch': 20.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8623635ba3e4a0e949b132c778cdc68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 1.6156260967254639, 'eval_runtime': 1.2649, 'eval_samples_per_second': 79.06, 'eval_steps_per_second': 5.534, 'epoch': 20.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "225d12524046418fafc391e70576f735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.75        58\n",
      "           1       0.66      0.69      0.67        42\n",
      "\n",
      "    accuracy                           0.72       100\n",
      "   macro avg       0.71      0.72      0.71       100\n",
      "weighted avg       0.72      0.72      0.72       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# ë°ì´í„° ì¤€ë¹„ (ì˜ˆì‹œ)\n",
    "# data = {\n",
    "#     'text': [\n",
    "#         'ì–´ë¬µê¹€ë§ì´: ë§›ìˆëŠ” ê¹€ë§ì´ì— ì«„ê¹ƒí•¨ì„ ë”í•œ ì–´ë¬µ ê¹€ë§ì´ì˜ˆìš”',\n",
    "#         'í˜„ë¯¸í˜¸ë‘ì£½: í˜„ë¯¸í˜¸ë‘ì£½',\n",
    "#         'ì°¸ì¹˜ì‚¼ê°ê¹€ë°¥: ë§¨ë‚  í¸ì˜ì ì—ì„œë§Œ ì‚¬ë¨¹ëŠ” ì‚¼ê°ê¹€ë°¥~ ì§‘ì—ì„œ ê°„í¸íˆ ë§Œë“¤ ìˆ˜ ìˆë‹¤ëŠ” ì‚¬ì‹¤~ ì°¸ì¹˜ë§Œ ìˆìœ¼ë©´ ëƒ‰ì¥ê³  ì—´ì–´ì„œ ë§Œë“¤ ìˆ˜ ìˆì–´ìš”~ í•œë¼ì‹ì‚¬ë¡œë„ ì¢‹ê³  ë„ì‹œë½ìœ¼ë¡œë„ ì¢‹ì€ ì°¸ì¹˜ì‚¼ê°ê¹€ë°¥ì„ ë§Œë“¤ì–´ ë³´ì•„ìš”~'\n",
    "#         # ì¶”ê°€ ë°ì´í„° 497ê°œ...\n",
    "#     ],\n",
    "#     'label': [1, 0, 0]  # ì¶”ê°€ ë°ì´í„° ë¼ë²¨...\n",
    "# }\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# BERT í† í¬ë‚˜ì´ì € ë° ëª¨ë¸ ë¡œë“œ\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-uncased', num_labels=2)\n",
    "\n",
    "# ë°ì´í„° ë¶„ë¦¬\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ì¤€ë¹„\n",
    "train_dataset = TextDataset(X_train.tolist(), y_train.tolist(), tokenizer, max_len=128)\n",
    "test_dataset = TextDataset(X_test.tolist(), y_test.tolist(), tokenizer, max_len=128)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "# í›ˆë ¨ ì„¤ì •\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=20,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ í›ˆë ¨\n",
    "trainer.train()\n",
    "\n",
    "# ëª¨ë¸ í‰ê°€\n",
    "results = trainer.evaluate()\n",
    "print(\"Evaluation results:\", results)\n",
    "\n",
    "# ì˜ˆì¸¡ ë° í‰ê°€\n",
    "preds_output = trainer.predict(test_dataset)\n",
    "preds = preds_output.predictions.argmax(-1)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[-3.3857,  3.7761]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "text = \"ìƒˆì½¤í•˜ê³  ë‹¬ì½¤í•˜ë‹ˆ ë§›ìˆëŠ” ì˜¤ì´ë¬´ì¹¨ì´ì—ìš”\"\n",
    "\n",
    "# í† í¬ë‚˜ì´ì§• ë° í…ì„œ ë³€í™˜\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "inputs = inputs.to(device)\n",
    "outputs = model(**inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
